# How I read? - Introduction to Scoopinion reading behavior data with R
### Juuso Parkkinen - @ouzor
### 16.6.2012

```{r setup, include=FALSE}
# upload images to imgur automatically 
opts_knit$set(upload.fun = imgur_upload)

# Load required libraries
library(ggplot2)
theme_set(theme_grey(16))

```

---

### Read and preprocess data

Read the JSON data file and preprocess reads data (see details in the [source code](scoopinion_functions.R))

```{r read_data, warning=FALSE}
source("scoopinion_functions.R")
reads.df <- PreprocessScoopinionData(filename="my_scoopinion_data.json")
```


---
### Filter data

```{r filter}
# Remove rare languages
table(reads.df$article.language)
reads.df <- droplevels(subset(reads.df, article.language %in% c("en", "fi")))

# Remove rare months
table(reads.df$Year.Month)
reads.df <- droplevels(subset(reads.df, Year.Month != "2013-04"))

# Study reads with repeating 'article.title'
repeats <- table(reads.df$article.title)
repeats <- repeats[repeats > 1]
print(repeats)
# Based on this, remove comics and Yle Areena
reads.to.remove <- which(reads.df$article.title %in% c("Anonyymit eläimet", "Fok_it", "Fok_it — Nyt", "Sarjakuvat", "Yle Areena"))
print(length(reads.to.remove))
reads.df <- droplevels(reads.df[-reads.to.remove, ])

# Remove very long articles
qplot(reads.df$article.word_count)
reads.df <- droplevels(subset(reads.df, article.word_count < 5000))
```

---
### List top sites

```{r top_sites}
# Most commonly read sites
head(sort(table(reads.df$article.site.name), decreasing=T), 10)

# Top referring sites
head(sort(table(reads.df$referrer), decreasing=T), 10)
```

---
### Study reading time vs. word count

```{r word_vs_time, message=FALSE, fig.width=8, fig.heigth=8}
# Average reading time vs. word count
ggplot(reads.df, aes(x=article.word_count, y=article.average_time, colour=article.language)) + geom_point(position=position_jitter(width=0, height=10))

# With fitted means
ggplot(reads.df, aes(x=article.word_count, y=article.average_time, colour=article.language)) + geom_point(position=position_jitter(width=0, height=10)) + geom_smooth(data=subset(reads.df, article.average_time>0))


# My personal reading time vs. words.read
ggplot(reads.df, aes(x=total_time, y=words_read, colour=article.language)) + geom_point()
# COMMENT: There appears to be a threshold for too high reading speed (a bit higher than 4 words / second)
# COMMENT: There are also a lot of reads with zero words read, probably some measuring errors
# QUESTION: Why some articles have 'average_time' zero?

# My personal reading time vs. article word count
ggplot(reads.df, aes(x=article.word_count, y=total_time, colour=article.language)) + geom_point()

# Personal words.read vs. article word count
ggplot(reads.df, aes(x=article.word_count, y=words_read, colour=article.language)) + geom_abline(slope=1, linetype="dashed") + geom_jitter()

# Compare my reading speed (total_time) to average
ggplot(reads.df, aes(x=article.average_time, y=total_time, colour=article.language)) + geom_abline(slope=1, linetype="dashed") + geom_jitter()
```

---
### Plot reading behaviour over time

```{r time, fig.width=10, fig.height=6}
# Histogram of daily reading counts
ggplot(reads.df, aes(x=Date, fill=article.language)) + geom_histogram(position="stack", binwidth=1)+ facet_wrap(~ Year, ncol=1, scales="free_x")

# Histogram of reading counts by weekdays, split by months
ggplot(reads.df, aes(x=WeekDay, fill=article.language)) + geom_histogram(position="stack", binwidth=1) + facet_wrap(~ Year.Month, ncol=5) + theme(axis.text.x=element_text(angle=45, vjust=0.8))

# Study development for top sites (HS,, etc.)
top10.sites <- names(head(sort(table(reads.df$article.site.name), decreasing=T), 10))
top10.df <- droplevels(subset(reads.df, article.site.name %in% top10.sites))
# Compute monthly averages
top10.montly.df <- plyr::ddply(top10.df, c("article.site.name", "Year.Month"), summarise, Average_reads=length(id))

# Position of HS paywall
paywall.pos <- which(unique(top10.montly.df$Year.Month)=="2012-11")
ggplot(top10.montly.df, aes(x=Year.Month, y=Average_reads, colour=article.site.name)) + geom_path(aes(group=article.site.name)) + geom_vline(xintercept=paywall.pos, linetype="dashed") + annotate("text", x=paywall.pos+0.1, y=40, label="HS paywall introduced 20.11.2012", hjust=0)
```


